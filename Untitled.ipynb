{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348c1939-e6f6-4752-bca2-53f240e8e1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from confluent_kafka import Consumer\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import from_json, when\n",
    "from pyspark.sql.types import StructType, StringType, IntegerType\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3a08a1-ef7c-4fc0-9d0c-8f5a9d3b49fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kafka configuration\n",
    "bootstrap_servers = 'localhost:9092'\n",
    "topic = 'streamTopic'\n",
    "group_id = 'group_id'\n",
    "\n",
    "conf = {\n",
    "    'bootstrap.servers': bootstrap_servers,\n",
    "    'group.id': group_id,\n",
    "    'auto.offset.reset': 'earliest'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40732c32-07cd-4f29-8b2f-c6cc26d71452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Kafka consumer\n",
    "consumer = Consumer(conf)\n",
    "consumer.subscribe([topic])\n",
    "access_key = \"AKIAZSSFLKRRD72NTUXF\"\n",
    "secret_access_key = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e280f309-304d-4499-8b50-ce68e91836d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"KafkaConsumerToS3\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.4.1\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.access.key\", access_key) \\\n",
    "    .config(\"spark.hadoop.fs.s3a.secret.key\", secret_access_key) \\\n",
    "    .config(\"spark.hadoop.fs.s3a.path.style.access\", \"True\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abcc3d9-246c-4f45-8012-8d85dae2a4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define schema for the incoming Kafka message\n",
    "schema = StructType() \\\n",
    "    .add(\"userid\", StringType()) \\\n",
    "    .add(\"user_location\", StringType()) \\\n",
    "    .add(\"channelid\", IntegerType()) \\\n",
    "    .add(\"genre\", StringType()) \\\n",
    "    .add(\"lastactive\", StringType()) \\\n",
    "    .add(\"title\", StringType()) \\\n",
    "    .add(\"watchfrequency\", IntegerType()) \\\n",
    "    .add(\"etags\", StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cea905-4c70-4aa1-9acf-c2cd9b49dcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Kafka messages in Spark Streaming\n",
    "kafka_df = spark.readStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", bootstrap_servers) \\\n",
    "    .option(\"subscribe\", topic) \\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44412410-0381-46ac-96f9-1f07a8a8ce5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the value column from Kafka into string and parse JSON\n",
    "parsed_df = kafka_df.selectExpr(\"CAST(value AS STRING)\") \\\n",
    "    .select(from_json(\"value\", schema).alias(\"data\")) \\\n",
    "    .select(\"data.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8773959e-9993-4868-a764-dc6d78c35959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform necessary transformations on the parsed data \n",
    "netflix_df = parsed_df.withColumn('impression',\n",
    "    when(parsed_df['watchfrequency'] < 3, \"neutral\")\n",
    "    .when(((parsed_df['watchfrequency'] >= 3) & (parsed_df['watchfrequency'] <= 10)), \"like\")\n",
    "    .otherwise(\"favorite\")\n",
    ")\n",
    "\n",
    "# Drop the etags values\n",
    "netflix_transformed_df = netflix_df.drop('etags')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32128f9-ca2f-475c-89b1-26ce3179c687",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"s3a://bibhusha-demo-bucket/streamData/\"\n",
    "query = netflix_transformed_df.writeStream \\\n",
    "    .format(\"parquet\") \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .option(\"checkpointLocation\", \"s3a://bibhusha-demo-bucket/checkpoint/\") \\\n",
    "    .start(output_path)\n",
    "\n",
    "# Await termination\n",
    "query.awaitTermination()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
